{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "libSM.so.6: cannot open shared object file: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-924e5d0d4842>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpreproc\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Documents/handwritingnotebook/src/data/preproc.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhtml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/cv2/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcv2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: libSM.so.6: cannot open shared object file: No such file or directory"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Bidirectional,Input\n",
    "from tensorflow.keras.layers import BatchNormalization, TimeDistributed,LSTM,Dropout,Reshape\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import Model\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import os\n",
    "from data import preproc as pp\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/home/austin/Documents/Github/handwritingnotebook/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_csv = pd.read_csv(data_dir+'words_csv/2020-06-03 11:39:42.000901.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 100\n",
    "IMG_HEIGHT = data_csv['height'].max()\n",
    "IMG_WIDTH = data_csv['width'].max()\n",
    "DATASET_SIZE = data_csv.shape[0]\n",
    "alphabet = \"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz.,()?!':; \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "464"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMG_HEIGHT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "783"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMG_WIDTH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/tutorials/load_data/images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset = tf.data.TextLineDataset(data_dir+'words_csv/2020-06-03 11:39:42.000901.csv').skip(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_onehot(data):\n",
    "    #Creates a dict, that maps to every char of alphabet an unique int based on position\n",
    "    char_to_int = dict((c,i) for i,c in enumerate(alphabet))\n",
    "    encoded_data = []\n",
    "    #Replaces every char in data with the mapped int\n",
    "    encoded_data.append([char_to_int[char] for char in data])\n",
    "    encoded_data = encoded_data[0] # Prints the int encoded array\n",
    "\n",
    "    #This part now replaces the int by an one-hot array with size alphabet\n",
    "    letter = [0. for _ in range(len(alphabet))]\n",
    "    for value in encoded_data:\n",
    "        #At first, the whole array is initialized with 0\n",
    "        #Only at the number of the int, 1 is written\n",
    "        letter[value] = 1.\n",
    "    letter = tf.convert_to_tensor(letter)\n",
    "    return letter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(img_path,data_dir):\n",
    "    img_path = data_dir + 'words_screenshot_labeled/' + img_path\n",
    "    img = tf.image.decode_png(tf.io.read_file(img_path),channels = 3)\n",
    "    img = tf.image.rgb_to_grayscale(img)\n",
    "    img = tf.image.resize_with_pad(img,IMG_HEIGHT,IMG_WIDTH)\n",
    "    img = tf.image.transpose(img)\n",
    "    img = img/255\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_img_dataset(dataset,data_dir):\n",
    "    img_dataset_list = []\n",
    "    for index, row in dataset.iterrows():\n",
    "        img_dataset_list.append(preprocess_image(row[0],data_dir))\n",
    "    data_as_dataset = tf.data.Dataset.from_tensor_slices(img_dataset_list)\n",
    "    return data_as_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_label_dataset(dataset):\n",
    "    label_dataset_list = []\n",
    "    for index, row in dataset.iterrows():\n",
    "        label_dataset_list.append(convert_to_onehot(row[1]))\n",
    "    data_as_dataset = tf.data.Dataset.from_tensor_slices(label_dataset_list)\n",
    "    return data_as_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = create_img_dataset(data_csv,data_dir)\n",
    "labels = create_label_dataset(data_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_ds = tf.data.Dataset.zip((imgs,labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.90 * DATASET_SIZE)\n",
    "test_size = int(0.10 * DATASET_SIZE)\n",
    "\n",
    "full_dataset = labeled_ds.shuffle(DATASET_SIZE)\n",
    "train_ds = full_dataset.take(train_size)\n",
    "train_ds = train_ds.batch(BATCH_SIZE, drop_remainder=True)\n",
    "test_ds = full_dataset.skip(train_size)\n",
    "test_ds = test_ds.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((100, 783, 464, 1), (100, 62)), types: (tf.float32, tf.float32)>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(Model):\n",
    "    def __init__(self,\n",
    "                 loss_object,\n",
    "                 optimizer,\n",
    "                 train_loss,\n",
    "                 train_metric,\n",
    "                 test_loss,\n",
    "                 test_metric):\n",
    "        '''\n",
    "            Setting all the variables for our model.\n",
    "        '''\n",
    "        super(MyModel, self).__init__()\n",
    "        self.cnn1 = Conv2D(filters = 32,\n",
    "                           kernel_size = (7, 7), \n",
    "                           padding=\"same\", \n",
    "                           activation=\"relu\", \n",
    "                           input_shape = (IMG_WIDTH,IMG_HEIGHT,1)\n",
    "                          )\n",
    "        self.norm1 = BatchNormalization(axis = 0)\n",
    "        self.maxp1 = MaxPooling2D(pool_size=(2, 2))\n",
    "        self.cnn2 = Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\")\n",
    "        self.norm2 = BatchNormalization()\n",
    "        self.maxp2 = MaxPooling2D(pool_size=(2, 2))\n",
    "        self.cnn3 = Conv2D(128, (3, 3), padding=\"same\", activation=\"relu\")\n",
    "        self.norm3 = BatchNormalization()\n",
    "        self.maxp3 = MaxPooling2D(pool_size=(2, 2))\n",
    "        self.cnn4 = Conv2D(256, (3, 3), padding=\"same\", activation=\"relu\")\n",
    "        self.norm4 = BatchNormalization()\n",
    "        self.maxp4 = MaxPooling2D(pool_size=(2, 2))\n",
    "    \n",
    "        self.loss_object = loss_object\n",
    "        self.optimizer = optimizer\n",
    "        self.train_loss = train_loss\n",
    "        self.train_metric = train_metric\n",
    "        self.test_loss = test_loss\n",
    "        self.test_metric = test_metric\n",
    "    def cnn_model(self, x):\n",
    "        '''\n",
    "            Defining the architecture of our model. This is where we run \n",
    "            through our whole dataset and return it, when training and \n",
    "            testing.\n",
    "        '''\n",
    "        x = self.cnn1(x)\n",
    "        print(x.get_shape())\n",
    "        x = self.norm1(x)\n",
    "        print(x.get_shape())\n",
    "        x = self.maxp1(x)\n",
    "        print(x.get_shape())\n",
    "        x = self.cnn2(x)\n",
    "        print(x.get_shape())\n",
    "        x = self.norm2(x)\n",
    "        print(x.get_shape())\n",
    "        x = self.maxp2(x)\n",
    "        print(x.get_shape())\n",
    "        x = self.cnn3(x)\n",
    "        print(x.get_shape())\n",
    "        x = self.norm3(x)\n",
    "        print(x.get_shape())\n",
    "        x = self.maxp3(x)\n",
    "        print(x.get_shape())\n",
    "        x = self.cnn4(x)\n",
    "        print(x.get_shape())\n",
    "        x = self.norm4(x)\n",
    "        print(x.get_shape())\n",
    "        x = self.maxp4(x)\n",
    "        print(x.get_shape())\n",
    "        shape = x.get_shape()\n",
    "        print(shape)\n",
    "        blstm = Reshape((shape[1], shape[2] * shape[3]))(x)\n",
    "        print(blstm.get_shape())\n",
    "        blstm = Bidirectional(LSTM(units=512, return_sequences=True, dropout=0.5))(blstm)\n",
    "        print(blstm.get_shape())\n",
    "        blstm = Bidirectional(LSTM(units=512, return_sequences=True, dropout=0.5))(blstm)\n",
    "        print(blstm.get_shape())\n",
    "        blstm = Bidirectional(LSTM(units=512, return_sequences=True, dropout=0.5))(blstm)\n",
    "        print(blstm.get_shape())\n",
    "        blstm = Bidirectional(LSTM(units=512, return_sequences=True, dropout=0.5))(blstm)\n",
    "        print(blstm.get_shape())\n",
    "        blstm = Bidirectional(LSTM(units=512, return_sequences=False, dropout=0.5))(blstm)\n",
    "        print(blstm.get_shape())\n",
    "        blstm = Dropout(rate=0.5)(blstm)\n",
    "        print(blstm.get_shape())\n",
    "        output_data = Dense(units=62, activation=\"softmax\")(blstm)\n",
    "        print(output_data.get_shape())\n",
    "        return(output_data)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    @tf.function\n",
    "    def train_step(self, images, labels):\n",
    "        '''\n",
    "            This is a TensorFlow function, run once for each epoch for the\n",
    "            whole input. We move forward first, then calculate gradients \n",
    "            with Gradient Tape to move backwards.\n",
    "        '''\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.cnn_model(images)\n",
    "            loss = self.loss_object(labels, predictions)\n",
    "        gradients = tape.gradient(loss, self.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(\n",
    "                                  gradients, self.trainable_variables))\n",
    "\n",
    "        self.train_loss(loss)\n",
    "        self.train_metric(labels, predictions)\n",
    "        \n",
    "    def fit(self, train, test, epochs):\n",
    "        '''\n",
    "            This fit function runs training and testing.\n",
    "        '''\n",
    "        for epoch in range(epochs):\n",
    "            for images, labels in train:\n",
    "                self.train_step(images, labels)\n",
    "\n",
    "            for test_images, test_labels in test:\n",
    "                self.test_step(test_images, test_labels)\n",
    "\n",
    "            template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'\n",
    "            print(template.format(epoch+1,\n",
    "                                  self.train_loss.result(),\n",
    "                                  self.train_metric.result()*100,\n",
    "                                  self.test_loss.result(),\n",
    "                                  self.test_metric.result()*100))\n",
    "\n",
    "            # Reset the metrics for the next epoch\n",
    "            self.train_loss.reset_states()\n",
    "            self.train_metric.reset_states()\n",
    "            self.test_loss.reset_states()\n",
    "            self.test_metric.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a loss object\n",
    "#loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "loss_object = tf.keras.losses.CategoricalCrossentropy()\n",
    "# Select the optimizer\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "# Specify metrics for training\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_metric = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "# Specify metrics for testing\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_metric = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the model\n",
    "model = MyModel(loss_object = loss_object,\n",
    "                optimizer = optimizer,\n",
    "                train_loss = train_loss,\n",
    "                train_metric = train_metric,\n",
    "                test_loss = test_loss,\n",
    "                test_metric = test_metric)\n",
    "\n",
    "EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 783, 464, 32)\n",
      "(100, 783, 464, 32)\n",
      "(100, 391, 232, 32)\n",
      "(100, 391, 232, 64)\n",
      "(100, 391, 232, 64)\n",
      "(100, 195, 116, 64)\n",
      "(100, 195, 116, 128)\n",
      "(100, 195, 116, 128)\n",
      "(100, 97, 58, 128)\n",
      "(100, 97, 58, 256)\n",
      "(100, 97, 58, 256)\n",
      "(100, 48, 29, 256)\n",
      "(100, 48, 29, 256)\n",
      "(100, 48, 7424)\n",
      "(100, 48, 1024)\n",
      "(100, 48, 1024)\n",
      "(100, 48, 1024)\n",
      "(100, 48, 1024)\n",
      "(100, 1024)\n",
      "(100, 1024)\n",
      "(100, 62)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    <ipython-input-131-aa89965ce1d9>:105 train_step  *\n        self.train_metric(labels, predictions)\n    /home/austin/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/keras/metrics.py:208 __call__  **\n        replica_local_fn, *args, **kwargs)\n    /home/austin/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/keras/distribute/distributed_training_utils.py:1133 call_replica_local_fn\n        return fn(*args, **kwargs)\n    /home/austin/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/keras/metrics.py:188 replica_local_fn\n        update_op = self.update_state(*args, **kwargs)  # pylint: disable=not-callable\n    /home/austin/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/keras/utils/metrics_utils.py:90 decorated\n        update_op = update_state_fn(*args, **kwargs)\n    /home/austin/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/keras/metrics.py:603 update_state\n        matches = self._fn(y_true, y_pred, **self._fn_kwargs)\n    /home/austin/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/keras/metrics.py:3244 sparse_categorical_accuracy\n        y_true = array_ops.squeeze(y_true, [-1])\n    /home/austin/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:180 wrapper\n        return target(*args, **kwargs)\n    /home/austin/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py:507 new_func\n        return func(*args, **kwargs)\n    /home/austin/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py:4145 squeeze\n        return gen_array_ops.squeeze(input, axis, name)\n    /home/austin/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/ops/gen_array_ops.py:9875 squeeze\n        \"Squeeze\", input=input, squeeze_dims=axis, name=name)\n    /home/austin/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:744 _apply_op_helper\n        attrs=attr_protos, op_def=op_def)\n    /home/austin/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py:595 _create_op_internal\n        compute_device)\n    /home/austin/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/framework/ops.py:3327 _create_op_internal\n        op_def=op_def)\n    /home/austin/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/framework/ops.py:1817 __init__\n        control_input_ops, op_def)\n    /home/austin/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/framework/ops.py:1657 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Can not squeeze dim[1], expected a dimension of 1, got 62 for '{{node Squeeze}} = Squeeze[T=DT_FLOAT, squeeze_dims=[-1]](labels)' with input shapes: [100,62].\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-145-fc266118c697>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m model.fit(train = train_ds,\n\u001b[1;32m      2\u001b[0m           \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m           epochs = EPOCHS)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-131-aa89965ce1d9>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, train, test, epochs)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    625\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    504\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    505\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 506\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2444\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2445\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2446\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2447\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2776\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2777\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2778\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2779\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2665\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2666\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2667\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2668\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2669\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    979\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mbound_method_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   3297\u001b[0m     \u001b[0;31m# However, the replacer is still responsible for attaching self properly.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3298\u001b[0m     \u001b[0;31m# TODO(mdan): Is it possible to do it here instead?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3299\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3300\u001b[0m   \u001b[0mweak_bound_method_wrapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_method_wrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 968\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    <ipython-input-131-aa89965ce1d9>:105 train_step  *\n        self.train_metric(labels, predictions)\n    /home/austin/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/keras/metrics.py:208 __call__  **\n        replica_local_fn, *args, **kwargs)\n    /home/austin/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/keras/distribute/distributed_training_utils.py:1133 call_replica_local_fn\n        return fn(*args, **kwargs)\n    /home/austin/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/keras/metrics.py:188 replica_local_fn\n        update_op = self.update_state(*args, **kwargs)  # pylint: disable=not-callable\n    /home/austin/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/keras/utils/metrics_utils.py:90 decorated\n        update_op = update_state_fn(*args, **kwargs)\n    /home/austin/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/keras/metrics.py:603 update_state\n        matches = self._fn(y_true, y_pred, **self._fn_kwargs)\n    /home/austin/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/keras/metrics.py:3244 sparse_categorical_accuracy\n        y_true = array_ops.squeeze(y_true, [-1])\n    /home/austin/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:180 wrapper\n        return target(*args, **kwargs)\n    /home/austin/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py:507 new_func\n        return func(*args, **kwargs)\n    /home/austin/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py:4145 squeeze\n        return gen_array_ops.squeeze(input, axis, name)\n    /home/austin/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/ops/gen_array_ops.py:9875 squeeze\n        \"Squeeze\", input=input, squeeze_dims=axis, name=name)\n    /home/austin/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:744 _apply_op_helper\n        attrs=attr_protos, op_def=op_def)\n    /home/austin/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py:595 _create_op_internal\n        compute_device)\n    /home/austin/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/framework/ops.py:3327 _create_op_internal\n        op_def=op_def)\n    /home/austin/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/framework/ops.py:1817 __init__\n        control_input_ops, op_def)\n    /home/austin/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/framework/ops.py:1657 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Can not squeeze dim[1], expected a dimension of 1, got 62 for '{{node Squeeze}} = Squeeze[T=DT_FLOAT, squeeze_dims=[-1]](labels)' with input shapes: [100,62].\n"
     ]
    }
   ],
   "source": [
    "model.fit(train = train_ds,\n",
    "          test = test_ds,\n",
    "          epochs = EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
