{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models, optimizers\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Bidirectional,Input\n",
    "from tensorflow.keras.layers import BatchNormalization, TimeDistributed,LSTM,Dropout,Reshape\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import Model\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import os\n",
    "from data import preproc as pp\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "import random\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/home/austin/Documents/Github/handwritingnotebook/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_csv = pd.read_csv(data_dir+'words_csv/2020-06-03 11:39:42.000901.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 100\n",
    "IMG_HEIGHT = data_csv['height'].max()\n",
    "IMG_WIDTH = data_csv['width'].max()\n",
    "DATASET_SIZE = data_csv.shape[0]\n",
    "alphabet = \"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz.,()?!':; \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "464"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMG_HEIGHT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "783"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMG_WIDTH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/tutorials/load_data/images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset = tf.data.TextLineDataset(data_dir+'words_csv/2020-06-03 11:39:42.000901.csv').skip(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_onehot(data):\n",
    "    #Creates a dict, that maps to every char of alphabet an unique int based on position\n",
    "    char_to_int = dict((c,i) for i,c in enumerate(alphabet))\n",
    "    encoded_data = []\n",
    "    #Replaces every char in data with the mapped int\n",
    "    encoded_data.append([char_to_int[char] for char in data])\n",
    "    encoded_data = encoded_data[0] # Prints the int encoded array\n",
    "\n",
    "    #This part now replaces the int by an one-hot array with size alphabet\n",
    "    letter = [0. for _ in range(len(alphabet))]\n",
    "    for value in encoded_data:\n",
    "        #At first, the whole array is initialized with 0\n",
    "        #Only at the number of the int, 1 is written\n",
    "        letter[value] = 1.\n",
    "    letter = tf.convert_to_tensor(letter)\n",
    "    return letter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def preprocess_image(img_path,data_dir):\n",
    "#     img_path = data_dir + 'words_screenshot_labeled/' + img_path\n",
    "#     img = tf.image.decode_png(tf.io.read_file(img_path),channels = 3)\n",
    "#     img = tf.image.rgb_to_grayscale(img)\n",
    "#     img = tf.image.resize_with_pad(img,IMG_HEIGHT,IMG_WIDTH)\n",
    "#     img = tf.image.transpose(img)\n",
    "#     img = img/255\n",
    "#     return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(img_path, data_dir, imgSize):\n",
    "    img_path = data_dir + 'words_screenshot_labeled/' + img_path\n",
    "    img = cv2.imread(img_path,0)\n",
    "    (wt, ht) = imgSize\n",
    "    (h, w) = img.shape\n",
    "    fx = w / wt\n",
    "    fy = h / ht\n",
    "    f = max(fx, fy)\n",
    "    newSize = (max(min(wt, int(w / f)), 1), max(min(ht, int(h / f)), 1)) # scale according to f (result at least 1 and at most wt or ht)\n",
    "    img = cv2.resize(img, newSize)\n",
    "    target = np.ones([ht, wt]) * 255\n",
    "    target[0:newSize[1], 0:newSize[0]] = img\n",
    "\n",
    "    # transpose for TF\n",
    "    img = cv2.transpose(target)\n",
    "\n",
    "    # normalize\n",
    "    (m, s) = cv2.meanStdDev(img)\n",
    "    m = m[0][0]\n",
    "    s = s[0][0]\n",
    "    img = img - m\n",
    "    img = img / s if s>0 else img\n",
    "    img = tf.convert_to_tensor(img)\n",
    "    img = tf.expand_dims(img,2)\n",
    "    print(img.get_shape())\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_img_dataset(dataset,data_dir):\n",
    "    img_dataset_list = []\n",
    "    for index, row in dataset.iterrows():\n",
    "        img_dataset_list.append(preprocess_image(row[0],data_dir,[128,32]))\n",
    "    data_as_dataset = tf.data.Dataset.from_tensor_slices(img_dataset_list)\n",
    "    return data_as_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_label_dataset(dataset):\n",
    "    label_dataset_list = []\n",
    "    for index, row in dataset.iterrows():\n",
    "        label_dataset_list.append(convert_to_onehot(row[1]))\n",
    "    data_as_dataset = tf.data.Dataset.from_tensor_slices(label_dataset_list)\n",
    "    return data_as_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n",
      "(128, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "imgs = create_img_dataset(data_csv,data_dir)\n",
    "labels = create_label_dataset(data_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_ds = tf.data.Dataset.zip((imgs,labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.90 * DATASET_SIZE)\n",
    "test_size = int(0.10 * DATASET_SIZE)\n",
    "\n",
    "full_dataset = labeled_ds.shuffle(DATASET_SIZE)\n",
    "train_ds = full_dataset.take(train_size)\n",
    "train_ds = train_ds.batch(BATCH_SIZE, drop_remainder=True)\n",
    "test_ds = full_dataset.skip(train_size)\n",
    "test_ds = test_ds.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((100, 128, 32, 1), (100, 62)), types: (tf.float64, tf.float32)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build(input_shape, classes):\n",
    "    # list of parameters for the layers\n",
    "    kernelVals = [5, 3, 3, 3]\n",
    "    featureVals = [64, 128, 128, 256]\n",
    "    poolVals = [(2,2), (1,2), (1,2), (1,2)]\n",
    "    numLayers = len(featureVals)\n",
    "    \n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(filters = 32,\n",
    "                                kernel_size = [5,5],\n",
    "                                padding = 'SAME',\n",
    "                                input_shape = (input_shape[0],input_shape[1],1)\n",
    "                               )\n",
    "                 )\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D(pool_size = poolVals[0],strides = poolVals[0]))\n",
    "    \n",
    "    for i in range(numLayers):\n",
    "        model.add(layers.Conv2D(filters = featureVals[i],\n",
    "                                kernel_size = [kernelVals[i],kernelVals[i]],\n",
    "                                padding = 'SAME'\n",
    "                               )\n",
    "                 )\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.MaxPooling2D(pool_size = poolVals[i],strides = poolVals[i]))\n",
    "    model.add(layers.Reshape((32,256)))\n",
    "    model.add(Bidirectional(LSTM(256,return_sequences = True)))\n",
    "    model.add(Bidirectional(LSTM(256,return_sequences = True)))\n",
    "    model.add(layers.Reshape((32,1,512)))\n",
    "    kernel = tf.Variable(tf.random.truncated_normal([1, 1, 512, 63], stddev=0.1))\n",
    "    model.add(layers.Conv2D(filters = kernel, kernel_size = [1,1),strides = (1,1),padding = 'SAME'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build([128,32,1],62)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPTIMIZER = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy',optimizer= OPTIMIZER,\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_41 (Conv2D)           (None, 128, 32, 32)       832       \n",
      "_________________________________________________________________\n",
      "batch_normalization_40 (Batc (None, 128, 32, 32)       128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_40 (MaxPooling (None, 64, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_42 (Conv2D)           (None, 64, 16, 64)        51264     \n",
      "_________________________________________________________________\n",
      "batch_normalization_41 (Batc (None, 64, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_41 (MaxPooling (None, 32, 8, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_43 (Conv2D)           (None, 32, 8, 128)        73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_42 (Batc (None, 32, 8, 128)        512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_42 (MaxPooling (None, 32, 4, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_44 (Conv2D)           (None, 32, 4, 128)        147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_43 (Batc (None, 32, 4, 128)        512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_43 (MaxPooling (None, 32, 2, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_45 (Conv2D)           (None, 32, 2, 256)        295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_44 (Batc (None, 32, 2, 256)        1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_44 (MaxPooling (None, 32, 1, 256)        0         \n",
      "_________________________________________________________________\n",
      "reshape_15 (Reshape)         (None, 32, 256)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_16 (Bidirectio (None, 32, 512)           1050624   \n",
      "_________________________________________________________________\n",
      "bidirectional_17 (Bidirectio (None, 32, 512)           1574912   \n",
      "_________________________________________________________________\n",
      "reshape_16 (Reshape)         (None, 32, 1, 512)        0         \n",
      "_________________________________________________________________\n",
      "reshape_17 (Reshape)         (None, 32, 80)            0         \n",
      "=================================================================\n",
      "Total params: 3,196,672\n",
      "Trainable params: 3,195,456\n",
      "Non-trainable params: 1,216\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
